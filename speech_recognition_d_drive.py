# speech_recognition_d_drive.py
import os
import sys

# æ·»åŠ Dç›˜Pythonçš„site-packagesåˆ°è·¯å¾„
d_python_lib = r"D:\python\Lib\site-packages"
if d_python_lib not in sys.path:
    sys.path.insert(0, d_python_lib)

os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

import pyaudio
import numpy as np
import time
import warnings

warnings.filterwarnings("ignore")


class DDriveSpeechRecognition:
    def __init__(self, model_size="base", language="zh"):
        print("=" * 60)
        print("Dç›˜Pythonè¯­éŸ³è¯†åˆ«ç³»ç»Ÿ")
        print("=" * 60)

        print(f"Pythonè·¯å¾„: {sys.executable}")
        print(f"Pythonç‰ˆæœ¬: {sys.version}")

        # æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–
        self._install_dependencies()

        # åŠ è½½æ¨¡å‹
        self._load_model(model_size, language)

        # éŸ³é¢‘è®¾ç½®
        self.CHUNK = 1024
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000

        print("ğŸ‰ Dç›˜Pythonè¯­éŸ³è¯†åˆ«ç³»ç»Ÿå°±ç»ªï¼")

    def _install_dependencies(self):
        """å®‰è£…å¿…è¦çš„ä¾èµ–"""
        # ä½¿ç”¨Dç›˜Pythonçš„pip
        pip_path = r"D:\python\Scripts\pip.exe"

        packages = [
            "openai-whisper",
            "pyaudio",
            "numpy"
        ]

        for package in packages:
            try:
                if package == "pyaudio":
                    import pyaudio
                elif package == "numpy":
                    import numpy
                elif package == "openai-whisper":
                    import whisper
                print(f"âœ… {package} å·²å®‰è£…")
            except ImportError:
                print(f"ğŸ“¥ å®‰è£… {package}...")
                os.system(f'"{pip_path}" install {package}')

    def _load_model(self, model_size, language):
        """åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹"""
        print("ğŸ“¥ åŠ è½½Whisperæ¨¡å‹...")

        import whisper

        try:
            # æ£€æŸ¥CUDA
            try:
                import torch
                if torch.cuda.is_available():
                    print("âœ… CUDAå¯ç”¨ï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
                    self.model = whisper.load_model(model_size)
                    print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ°: {self.model.device}")
                else:
                    print("â„¹ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
                    self.model = whisper.load_model(model_size)
            except:
                print("â„¹ï¸ ä½¿ç”¨é»˜è®¤æ¨¡å¼åŠ è½½æ¨¡å‹")
                self.model = whisper.load_model(model_size)

            self.language = language

            # é¢„çƒ­
            print("ğŸ”¥ é¢„çƒ­æ¨¡å‹...")
            dummy_audio = np.random.random(16000).astype(np.float32)
            _ = self.model.transcribe(dummy_audio, language=language)

        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def record_audio(self, duration=5):
        """å½•åˆ¶éŸ³é¢‘"""
        print(f"\nğŸ¤ å¼€å§‹å½•åˆ¶ {duration} ç§’...")

        try:
            p = pyaudio.PyAudio()

            # æ˜¾ç¤ºéŸ³é¢‘è®¾å¤‡ä¿¡æ¯
            try:
                default_input = p.get_default_input_device_info()
                print(f"ğŸ“± ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {default_input['name']}")
            except:
                print("ğŸ“± ä½¿ç”¨é»˜è®¤éŸ³é¢‘è®¾å¤‡")

            stream = p.open(
                format=self.FORMAT,
                channels=self.CHANNELS,
                rate=self.RATE,
                input=True,
                frames_per_buffer=self.CHUNK
            )

            frames = []
            start_time = time.time()

            for i in range(0, int(self.RATE / self.CHUNK * duration)):
                data = stream.read(self.CHUNK, exception_on_overflow=False)
                frames.append(data)

                elapsed = time.time() - start_time
                progress = (elapsed / duration) * 100
                if i % 10 == 0:
                    print(f"\râºï¸ å½•éŸ³è¿›åº¦: {progress:.1f}%", end="", flush=True)

            stream.stop_stream()
            stream.close()
            p.terminate()

            print("\nâœ… å½•éŸ³å®Œæˆ")

            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            audio_data = np.frombuffer(b''.join(frames), dtype=np.int16)
            audio_float = audio_data.astype(np.float32) / 32768.0

            return audio_float

        except Exception as e:
            print(f"âŒ å½•éŸ³é”™è¯¯: {e}")
            return None

    def transcribe_audio(self, audio_array):
        """è½¬å½•éŸ³é¢‘"""
        if audio_array is None:
            return "âŒ å½•éŸ³å¤±è´¥"

        print("ğŸ¯ è½¬å½•ä¸­...")
        start_time = time.time()

        try:
            result = self.model.transcribe(
                audio_array,
                language=self.language,
                temperature=0.0
            )

            transcription_time = time.time() - start_time
            text = result["text"].strip()

            print(f"\nğŸ“Š è½¬å½•è€—æ—¶: {transcription_time:.2f}ç§’")
            print(f"ğŸš€ å¤„ç†é€Ÿåº¦: {5.0 / transcription_time:.1f}xå®æ—¶")

            return text

        except Exception as e:
            print(f"âŒ è½¬å½•é”™è¯¯: {e}")
            return f"è½¬å½•å¤±è´¥: {e}"

    def start_demo(self):
        """å¼€å§‹æ¼”ç¤º"""
        print("\n" + "=" * 50)
        print("ğŸ¯ Dç›˜Pythonè¯­éŸ³è¯†åˆ«æ¼”ç¤º")
        print("=" * 50)
        print("æŒ‰ Ctrl+C é€€å‡ºç¨‹åº")
        print("=" * 50)

        try:
            while True:
                input("\nğŸ¯ æŒ‰å›è½¦å¼€å§‹å½•éŸ³ (5ç§’)...")

                # å½•åˆ¶å’Œè½¬å½•
                audio_data = self.record_audio(5)
                result = self.transcribe_audio(audio_data)

                print(f"\nğŸ—£ï¸  è¯†åˆ«ç»“æœ: {result}")
                print("-" * 50)

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹åºç»“æŸ")
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    try:
        # å¯åŠ¨è¯­éŸ³è¯†åˆ«
        stt = DDriveSpeechRecognition(model_size="base", language="zh")
        stt.start_demo()

    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")