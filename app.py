# faster_realtime_asr.py
from faster_whisper import WhisperModel
import pyaudio
import numpy as np
import threading
import time
import queue
import tkinter as tk
from tkinter import ttk, scrolledtext
import os


class FasterRealtimeASR:
    def __init__(self, model_size="large-v2", sample_rate=16000, chunk_duration=3.0):
        self.sample_rate = sample_rate
        self.chunk_duration = chunk_duration
        self.chunk_samples = int(sample_rate * chunk_duration)

        # æ€§èƒ½å‚æ•°
        self.silence_threshold = 0.01
        self.min_audio_length = 1.0

        print(f"ğŸš€ åˆå§‹åŒ–faster-whisperå®æ—¶è½¬å½•ç³»ç»Ÿ...")
        print(f"   æ¨¡å‹: {model_size}")
        print(f"   é‡‡æ ·ç‡: {sample_rate}Hz")
        print(f"   å—æ—¶é•¿: {chunk_duration}ç§’")

        # åŠ è½½faster-whisperæ¨¡å‹
        self.model = self.load_faster_whisper_model(model_size)

        # éŸ³é¢‘å¤„ç†
        self.audio_queue = queue.Queue(maxsize=20)
        self.is_recording = False
        self.is_processing = False
        self.transcription_history = []

        # PyAudioå®ä¾‹
        self.p = pyaudio.PyAudio()

        # GUIç›¸å…³
        self.root = None
        self.text_widget = None
        self.status_var = None

        print("âœ… faster-whisperç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")

    def load_faster_whisper_model(self, model_size):
        """åŠ è½½faster-whisperæ¨¡å‹"""
        print(f"ğŸ“¥ åŠ è½½faster-whisperæ¨¡å‹: {model_size}")

        try:
            model = WhisperModel(
                model_size,
                device="cuda",
                compute_type="float16",
                download_root="./whisper_models"
            )
            print("   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (CUDA)")
            return model
        except Exception as e:
            print(f"âŒ CUDAåŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ å°è¯•ä½¿ç”¨CPU...")
            try:
                model = WhisperModel(
                    model_size,
                    device="cpu",
                    compute_type="int8",
                    download_root="./whisper_models"
                )
                print("   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (CPU)")
                return model
            except Exception as e2:
                print(f"âŒ æ¨¡å‹åŠ è½½å®Œå…¨å¤±è´¥: {e2}")
                raise e2

    def find_audio_input_device(self):
        """æŸ¥æ‰¾éŸ³é¢‘è¾“å…¥è®¾å¤‡"""
        print("ğŸ” æ‰«æéŸ³é¢‘è¾“å…¥è®¾å¤‡...")

        input_devices = []
        for i in range(self.p.get_device_count()):
            device_info = self.p.get_device_info_by_index(i)
            if device_info['maxInputChannels'] > 0:
                input_devices.append({
                    'index': i,
                    'name': device_info['name'],
                    'channels': device_info['maxInputChannels'],
                    'sample_rate': device_info['defaultSampleRate']
                })
                print(f"   ğŸ“¢ {i}: {device_info['name']} (é€šé“: {device_info['maxInputChannels']})")

        if not input_devices:
            raise Exception("æœªæ‰¾åˆ°å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡")

        # é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„è¾“å…¥è®¾å¤‡
        selected_device = input_devices[0]
        print(f"âœ… é€‰æ‹©è®¾å¤‡: {selected_device['name']}")
        return selected_device['index']

    def audio_capture_thread(self):
        """éŸ³é¢‘æ•è·çº¿ç¨‹"""
        device_index = self.find_audio_input_device()

        stream = self.p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self.sample_rate,
            input=True,
            input_device_index=device_index,
            frames_per_buffer=1024
        )

        print("ğŸ¤ å¼€å§‹éŸ³é¢‘æ•è·...")

        try:
            while self.is_recording:
                # è¯»å–éŸ³é¢‘æ•°æ®
                data = stream.read(1024, exception_on_overflow=False)
                audio_chunk = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0

                # æ”¾å…¥é˜Ÿåˆ—ï¼ˆéé˜»å¡ï¼‰
                if not self.audio_queue.full():
                    self.audio_queue.put(audio_chunk, block=False)

        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ•è·é”™è¯¯: {e}")
        finally:
            stream.stop_stream()
            stream.close()

    def calculate_audio_energy(self, audio_chunk):
        """è®¡ç®—éŸ³é¢‘èƒ½é‡"""
        return np.sqrt(np.mean(audio_chunk ** 2))

    def is_valid_audio(self, audio_chunk):
        """æ£€æµ‹æ˜¯å¦ä¸ºæœ‰æ•ˆéŸ³é¢‘"""
        energy = self.calculate_audio_energy(audio_chunk)
        return energy > self.silence_threshold

    def transcribe_audio(self, audio_data):
        """ä½¿ç”¨faster-whisperè½¬å½•éŸ³é¢‘"""
        try:
            segments, info = self.model.transcribe(
                audio_data,
                language="zh",
                beam_size=3,
                best_of=2,
                temperature=0.0,
                vad_filter=True,
                vad_parameters=dict(
                    min_silence_duration_ms=500,
                    speech_pad_ms=200
                ),
                without_timestamps=True
            )

            texts = []
            for segment in segments:
                if segment.text.strip():
                    texts.append(segment.text.strip())

            return " ".join(texts).strip() if texts else None

        except Exception as e:
            print(f"âŒ è½¬å½•é”™è¯¯: {e}")
            return None

    def process_audio_stream(self):
        """å¤„ç†éŸ³é¢‘æµ"""
        audio_buffer = []
        silence_counter = 0
        last_transcription = ""

        while self.is_processing:
            try:
                # è·å–éŸ³é¢‘æ•°æ®
                audio_chunk = self.audio_queue.get(timeout=1.0)
                audio_buffer.extend(audio_chunk)

                # å½“æœ‰è¶³å¤Ÿæ•°æ®æ—¶å¤„ç†
                while len(audio_buffer) >= self.chunk_samples:
                    chunk_to_process = audio_buffer[:self.chunk_samples]
                    audio_buffer = audio_buffer[self.chunk_samples:]

                    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆéŸ³é¢‘
                    if self.is_valid_audio(np.array(chunk_to_process)):
                        # è½¬å½•
                        transcription = self.transcribe_audio(np.array(chunk_to_process))

                        if transcription and transcription != last_transcription:
                            current_time = time.strftime("%H:%M:%S")
                            result_text = f"[{current_time}] ğŸ¯ {transcription}"

                            # æ›´æ–°GUI
                            if self.text_widget:
                                self.root.after(0, self.update_text_widget, result_text)

                            print(f"\r{result_text}" + " " * 50)

                            self.transcription_history.append({
                                'time': current_time,
                                'text': transcription
                            })
                            last_transcription = transcription

                            silence_counter = 0
                            if self.status_var:
                                self.root.after(0, lambda: self.status_var.set("çŠ¶æ€: æ£€æµ‹åˆ°è¯­éŸ³"))
                        else:
                            silence_counter += 1
                    else:
                        silence_counter += 1

                    # é™éŸ³çŠ¶æ€æ›´æ–°
                    if silence_counter > 0 and silence_counter % 10 == 0 and self.status_var:
                        self.root.after(0, lambda: self.status_var.set(f"çŠ¶æ€: ç›‘å¬ä¸­... (é™éŸ³{silence_counter}æ¬¡)"))

            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ å¤„ç†é”™è¯¯: {e}")
                if self.status_var:
                    self.root.after(0, lambda: self.status_var.set(f"çŠ¶æ€: é”™è¯¯ - {e}"))

    def update_text_widget(self, text):
        """æ›´æ–°æ–‡æœ¬æ˜¾ç¤º"""
        if self.text_widget:
            self.text_widget.insert(tk.END, text + "\n")
            self.text_widget.see(tk.END)

    def start_transcription(self):
        """å¼€å§‹è½¬å½•"""
        if self.is_recording:
            self.update_status("âš ï¸ è½¬å½•å·²åœ¨è¿è¡Œä¸­")
            return

        print("\nğŸ¤ å¼€å§‹å®æ—¶è¯­éŸ³è½¬å½•...")

        self.is_recording = True
        self.is_processing = True

        self.update_status("çŠ¶æ€: å¯åŠ¨ä¸­...")

        # å¯åŠ¨éŸ³é¢‘æ•è·çº¿ç¨‹
        audio_thread = threading.Thread(target=self.audio_capture_thread)
        audio_thread.daemon = True
        audio_thread.start()

        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        process_thread = threading.Thread(target=self.process_audio_stream)
        process_thread.daemon = True
        process_thread.start()

        self.update_status("çŠ¶æ€: å½•éŸ³ä¸­...è¯·å¼€å§‹è¯´è¯")

    def stop_transcription(self):
        """åœæ­¢è½¬å½•"""
        if not self.is_recording:
            return

        print("\nğŸ›‘ åœæ­¢è½¬å½•ç³»ç»Ÿ...")
        self.is_recording = False
        self.is_processing = False

        self.update_status("çŠ¶æ€: å·²åœæ­¢")

        # æ˜¾ç¤ºç»Ÿè®¡
        if self.transcription_history:
            print(f"\nğŸ“Š æœ¬æ¬¡ä¼šè¯ç»Ÿè®¡:")
            print(f"   è½¬å½•ç‰‡æ®µ: {len(self.transcription_history)}")
            if self.transcription_history:
                print(f"   æœ€åä¸€æ¡: {self.transcription_history[-1]['text']}")

    def update_status(self, message):
        """æ›´æ–°çŠ¶æ€"""
        if self.status_var and self.root:
            self.root.after(0, lambda: self.status_var.set(message))

    def save_transcription(self, filename=None):
        """ä¿å­˜è½¬å½•ç»“æœ"""
        if not self.transcription_history:
            self.update_status("âš ï¸ æ²¡æœ‰è½¬å½•ç»“æœå¯ä¿å­˜")
            return

        if filename is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"transcription_{timestamp}.txt"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write("faster-whisperå®æ—¶è½¬å½•è®°å½•\n")
                f.write("=" * 50 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ€»è®°å½•æ•°: {len(self.transcription_history)}\n")
                f.write("=" * 50 + "\n\n")

                for i, item in enumerate(self.transcription_history, 1):
                    f.write(f"{i:02d}. [{item['time']}] {item['text']}\n")

            print(f"âœ… è½¬å½•ç»“æœå·²ä¿å­˜åˆ°: {filename}")
            self.update_status(f"âœ… å·²ä¿å­˜: {filename}")
            return filename

        except Exception as e:
            error_msg = f"âŒ ä¿å­˜å¤±è´¥: {e}"
            print(error_msg)
            self.update_status(error_msg)
            return None

    def create_gui(self):
        """åˆ›å»ºGUIç•Œé¢"""
        self.root = tk.Tk()
        self.root.title("faster-whisperå®æ—¶è½¬å½•ç³»ç»Ÿ")
        self.root.geometry("900x700")
        self.root.configure(bg='#f0f0f0')

        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root, padding="15")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # æ ‡é¢˜
        title_label = ttk.Label(main_frame,
                                text="ğŸ¤ faster-whisperå®æ—¶è¯­éŸ³è½¬å½•",
                                font=('Arial', 16, 'bold'))
        title_label.grid(row=0, column=0, columnspan=4, pady=(0, 15))

        # çŠ¶æ€æ˜¾ç¤º
        self.status_var = tk.StringVar(value="çŠ¶æ€: å°±ç»ª")
        status_label = ttk.Label(main_frame, textvariable=self.status_var,
                                 font=('Arial', 11), foreground='blue')
        status_label.grid(row=1, column=0, columnspan=4, pady=(0, 10))

        # æ§åˆ¶æŒ‰é’®
        button_frame = ttk.Frame(main_frame)
        button_frame.grid(row=2, column=0, columnspan=4, pady=(0, 15))

        start_btn = ttk.Button(button_frame, text="ğŸ¤ å¼€å§‹è½¬å½•",
                               command=self.start_transcription, width=15)
        start_btn.grid(row=0, column=0, padx=5)

        stop_btn = ttk.Button(button_frame, text="â¹ï¸ åœæ­¢è½¬å½•",
                              command=self.stop_transcription, width=15)
        stop_btn.grid(row=0, column=1, padx=5)

        save_btn = ttk.Button(button_frame, text="ğŸ’¾ ä¿å­˜ç»“æœ",
                              command=self.save_transcription, width=15)
        save_btn.grid(row=0, column=2, padx=5)

        clear_btn = ttk.Button(button_frame, text="ğŸ—‘ï¸ æ¸…ç©ºè®°å½•",
                               command=self.clear_text, width=15)
        clear_btn.grid(row=0, column=3, padx=5)

        # è½¬å½•ç»“æœæ˜¾ç¤º
        text_frame = ttk.LabelFrame(main_frame, text="å®æ—¶è½¬å½•ç»“æœ", padding="8")
        text_frame.grid(row=3, column=0, columnspan=4, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 15))

        self.text_widget = scrolledtext.ScrolledText(
            text_frame,
            wrap=tk.WORD,
            width=100,
            height=25,
            font=('Arial', 10),
            bg='#fafafa'
        )
        self.text_widget.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # ç³»ç»Ÿä¿¡æ¯
        info_frame = ttk.LabelFrame(main_frame, text="ç³»ç»Ÿä¿¡æ¯", padding="8")
        info_frame.grid(row=4, column=0, columnspan=4, sticky=(tk.W, tk.E))

        info_text = f"""
æ¨¡å‹: faster-whisper large-v2 | è®¾å¤‡: CUDA | é‡‡æ ·ç‡: {self.sample_rate}Hz
ç‰¹æ€§: VADè¯­éŸ³æ£€æµ‹ | å®æ—¶è½¬å½• | ä¸­æ–‡ä¼˜åŒ– | ä½å»¶è¿Ÿ
æç¤º: è¯´è¯æ¸…æ™°ï¼Œä¿æŒé€‚å½“è·ç¦»ï¼Œå‡å°‘èƒŒæ™¯å™ªéŸ³
        """
        info_label = ttk.Label(info_frame, text=info_text.strip(), justify=tk.LEFT)
        info_label.grid(row=0, column=0, sticky=tk.W)

        # é…ç½®ç½‘æ ¼
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(0, weight=1)
        main_frame.rowconfigure(3, weight=1)
        text_frame.columnconfigure(0, weight=1)
        text_frame.rowconfigure(0, weight=1)

        # ç»‘å®šå…³é—­äº‹ä»¶
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)

        return self.root

    def clear_text(self):
        """æ¸…ç©ºæ–‡æœ¬"""
        if self.text_widget:
            self.text_widget.delete(1.0, tk.END)
        self.transcription_history.clear()
        self.update_status("ğŸ“ è½¬å½•è®°å½•å·²æ¸…ç©º")
        print("ğŸ“ è½¬å½•è®°å½•å·²æ¸…ç©º")

    def on_closing(self):
        """å…³é—­å¤„ç†"""
        self.stop_transcription()
        self.p.terminate()
        self.root.destroy()
        print("ğŸ‘‹ ç¨‹åºå·²å®‰å…¨é€€å‡º")

    def run_gui(self):
        """è¿è¡ŒGUI"""
        if self.root is None:
            self.create_gui()

        print("ğŸ® å¯åŠ¨å›¾å½¢ç•Œé¢...")
        print("ğŸ’¡ æç¤º: ç¡®ä¿éº¦å…‹é£æƒé™å·²å¼€å¯")

        try:
            self.root.mainloop()
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        finally:
            self.stop_transcription()
            self.p.terminate()


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ faster-whisperå®æ—¶è¯­éŸ³è½¬å½•ç³»ç»Ÿ")
    print("   åŸºäºfaster-whisperæŠ€æœ¯")
    print("   CUDAåŠ é€Ÿç‰ˆæœ¬")
    print("=" * 60)

    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        asr_system = FasterRealtimeASR(
            model_size="large-v2",  # ä½¿ç”¨large-v2æ¨¡å‹
            sample_rate=16000,
            chunk_duration=3.0
        )

        # å¯åŠ¨å›¾å½¢ç•Œé¢
        asr_system.run_gui()

    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        print("\nğŸ’¡ è¯·ç¡®ä¿å·²å®‰è£…: pip install faster-whisper pyaudio")


if __name__ == "__main__":
    main()